{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Julia",
      "language": "julia",
      "name": "julia"
    },
    "language_info": {
      "file_extension": ".jl",
      "mimetype": "application/julia",
      "name": "julia"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/visuddhi/JuMP-Tutorials/blob/master/Julia_Colab_Notebook_Tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQ1r1bbb0yBv"
      },
      "source": [
        "# <img src=\"https://github.com/JuliaLang/julia-logo-graphics/raw/master/images/julia-logo-color.png\" height=\"100\" /> _Colab Notebook Template_\n",
        "\n",
        "## Instructions\n",
        "1. Work on a copy of this notebook: _File_ > _Save a copy in Drive_ (you will need a Google account). Alternatively, you can download the notebook using _File_ > _Download .ipynb_, then upload it to [Colab](https://colab.research.google.com/).\n",
        "2. If you need a GPU: _Runtime_ > _Change runtime type_ > _Harware accelerator_ = _GPU_.\n",
        "3. Execute the following cell (click on it and press Ctrl+Enter) to install Julia, IJulia and other packages (if needed, update `JULIA_VERSION` and the other parameters). This takes a couple of minutes.\n",
        "4. Reload this page (press Ctrl+R, or ⌘+R, or the F5 key) and continue to the next section.\n",
        "\n",
        "_Notes_:\n",
        "* If your Colab Runtime gets reset (e.g., due to inactivity), repeat steps 2, 3 and 4.\n",
        "* After installation, if you want to change the Julia version or activate/deactivate the GPU, you will need to reset the Runtime: _Runtime_ > _Factory reset runtime_ and repeat steps 3 and 4."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GIeFXS0F0zww",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "db07507b-6f53-4ce9-c612-e6c22690453d"
      },
      "source": [
        "%%shell\n",
        "set -e\n",
        "\n",
        "#---------------------------------------------------#\n",
        "JULIA_VERSION=\"1.8.2\" # any version ≥ 0.7.0\n",
        "JULIA_PACKAGES=\"IJulia BenchmarkTools\"\n",
        "JULIA_PACKAGES_IF_GPU=\"CUDA\" # or CuArrays for older Julia versions\n",
        "JULIA_NUM_THREADS=2\n",
        "#---------------------------------------------------#\n",
        "\n",
        "if [ -z `which julia` ]; then\n",
        "  # Install Julia\n",
        "  JULIA_VER=`cut -d '.' -f -2 <<< \"$JULIA_VERSION\"`\n",
        "  echo \"Installing Julia $JULIA_VERSION on the current Colab Runtime...\"\n",
        "  BASE_URL=\"https://julialang-s3.julialang.org/bin/linux/x64\"\n",
        "  URL=\"$BASE_URL/$JULIA_VER/julia-$JULIA_VERSION-linux-x86_64.tar.gz\"\n",
        "  wget -nv $URL -O /tmp/julia.tar.gz # -nv means \"not verbose\"\n",
        "  tar -x -f /tmp/julia.tar.gz -C /usr/local --strip-components 1\n",
        "  rm /tmp/julia.tar.gz\n",
        "\n",
        "  # Install Packages\n",
        "  nvidia-smi -L &> /dev/null && export GPU=1 || export GPU=0\n",
        "  if [ $GPU -eq 1 ]; then\n",
        "    JULIA_PACKAGES=\"$JULIA_PACKAGES $JULIA_PACKAGES_IF_GPU\"\n",
        "  fi\n",
        "  for PKG in `echo $JULIA_PACKAGES`; do\n",
        "    echo \"Installing Julia package $PKG...\"\n",
        "    julia -e 'using Pkg; pkg\"add '$PKG'; precompile;\"' &> /dev/null\n",
        "  done\n",
        "\n",
        "  # Install kernel and rename it to \"julia\"\n",
        "  echo \"Installing IJulia kernel...\"\n",
        "  julia -e 'using IJulia; IJulia.installkernel(\"julia\", env=Dict(\n",
        "      \"JULIA_NUM_THREADS\"=>\"'\"$JULIA_NUM_THREADS\"'\"))'\n",
        "  KERNEL_DIR=`julia -e \"using IJulia; print(IJulia.kerneldir())\"`\n",
        "  KERNEL_NAME=`ls -d \"$KERNEL_DIR\"/julia*`\n",
        "  mv -f $KERNEL_NAME \"$KERNEL_DIR\"/julia\n",
        "\n",
        "  echo ''\n",
        "  echo \"Successfully installed `julia -v`!\"\n",
        "  echo \"Please reload this page (press Ctrl+R, ⌘+R, or the F5 key) then\"\n",
        "  echo \"jump to the 'Checking the Installation' section.\"\n",
        "fi"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  Unrecognized magic \u001b[36m%%shell\u001b[39m.\n",
              "\n",
              "  Julia does not use the IPython \u001b[36m%magic\u001b[39m syntax. To interact with the IJulia kernel, use\n",
              "  \u001b[36mIJulia.somefunction(...)\u001b[39m, for example. Julia macros, string macros, and functions can be used to\n",
              "  accomplish most of the other functionalities of IPython magics."
            ],
            "text/markdown": "Unrecognized magic `%%shell`.\n\nJulia does not use the IPython `%magic` syntax.   To interact with the IJulia kernel, use `IJulia.somefunction(...)`, for example.  Julia macros, string macros, and functions can be used to accomplish most of the other functionalities of IPython magics.\n",
            "text/latex": "Unrecognized magic \\texttt{\\%\\%shell}.\n\nJulia does not use the IPython \\texttt{\\%magic} syntax.   To interact with the IJulia kernel, use \\texttt{IJulia.somefunction(...)}, for example.  Julia macros, string macros, and functions can be used to accomplish most of the other functionalities of IPython magics.\n\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-OS3Ac017T1i"
      },
      "source": [
        "# Checking the Installation\n",
        "The `versioninfo()` function should print your Julia version and some other info about the system:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EEzvvzCl1i0F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18e5a031-5fe2-4d6a-8d93-9151a9fc7c87"
      },
      "source": [
        "versioninfo()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Julia Version 1.8.2\n",
            "Commit 36034abf260 (2022-09-29 15:21 UTC)\n",
            "Platform Info:\n",
            "  OS: Linux (x86_64-linux-gnu)\n",
            "  CPU: 2 × Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "  WORD_SIZE: 64\n",
            "  LIBM: libopenlibm\n",
            "  LLVM: libLLVM-13.0.1 (ORCJIT, broadwell)\n",
            "  Threads: 2 on 2 virtual cores\n",
            "Environment:\n",
            "  LD_LIBRARY_PATH = /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
            "  JULIA_NUM_THREADS = 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "using BenchmarkTools\n",
        "\n",
        "M = rand(2^11, 2^11)\n",
        "\n",
        "@btime $M * $M;"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YjM_qq54lCcs",
        "outputId": "f75fb86b-e1c9-47cc-a091-9fe30078ce5f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  547.716 ms (2 allocations: 32.00 MiB)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XciCcMAJOT3_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12c72182-4a40-4586-cccf-2d619e7612fa"
      },
      "source": [
        "try\n",
        "    using CUDA\n",
        "catch\n",
        "    println(\"No GPU found.\")\n",
        "else\n",
        "    run(`nvidia-smi`)\n",
        "    # Create a new random matrix directly on the GPU:\n",
        "    M_on_gpu = CUDA.CURAND.rand(2^11, 2^11)\n",
        "    @btime $M_on_gpu * $M_on_gpu; nothing\n",
        "end"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No GPU found.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import Pkg\n",
        "Pkg.add(\"JuMP\")\n",
        "Pkg.add(\"HiGHS\")"
      ],
      "metadata": {
        "id": "z0g-jm4jU9EU",
        "outputId": "89e1dfcf-ed5e-4c45-8b13-b3bae5beb2d7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m HiGHS_jll ─ v1.9.0+0\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m HiGHS ───── v1.13.0\n",
            "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.8/Project.toml`\n",
            " \u001b[90m [87dc4568] \u001b[39m\u001b[92m+ HiGHS v1.13.0\u001b[39m\n",
            "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.8/Manifest.toml`\n",
            " \u001b[90m [87dc4568] \u001b[39m\u001b[92m+ HiGHS v1.13.0\u001b[39m\n",
            " \u001b[90m [8fd58aa0] \u001b[39m\u001b[92m+ HiGHS_jll v1.9.0+0\u001b[39m\n",
            "\u001b[32m\u001b[1mPrecompiling\u001b[22m\u001b[39m project...\n",
            "\u001b[32m  ✓ \u001b[39m\u001b[90mHiGHS_jll\u001b[39m\n",
            "\u001b[32m  ✓ \u001b[39mHiGHS\n",
            "  2 dependencies successfully precompiled in 27 seconds. 49 already precompiled.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "using JuMP\n",
        "import HiGHS"
      ],
      "metadata": {
        "id": "unLp6CNbVHYl"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n = 5;\n",
        "capacity = 10.0;\n",
        "profit = [5.0, 3.0, 2.0, 7.0, 4.0];\n",
        "weight = [2.0, 8.0, 4.0, 2.0, 5.0];\n",
        "model = Model(HiGHS.Optimizer)\n",
        "@variable(model, x[1:n], Bin)\n",
        "@constraint(model, sum(weight[i] * x[i] for i in 1:n) <= capacity)\n",
        "@objective(model, Max, sum(profit[i] * x[i] for i in 1:n))\n",
        "print(model)"
      ],
      "metadata": {
        "id": "bCQpVYJQWBEm",
        "outputId": "e2cd5bf0-655b-474a-fad0-8d7dd2bb4f28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/latex": "$$ \\begin{aligned}\n\\max\\quad & 5 x_{1} + 3 x_{2} + 2 x_{3} + 7 x_{4} + 4 x_{5}\\\\\n\\text{Subject to} \\quad & 2 x_{1} + 8 x_{2} + 4 x_{3} + 2 x_{4} + 5 x_{5} \\leq 10\\\\\n & x_{1} \\in \\{0, 1\\}\\\\\n & x_{2} \\in \\{0, 1\\}\\\\\n & x_{3} \\in \\{0, 1\\}\\\\\n & x_{4} \\in \\{0, 1\\}\\\\\n & x_{5} \\in \\{0, 1\\}\\\\\n\\end{aligned} $$"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimize!(model)\n",
        "@assert is_solved_and_feasible(model)\n",
        "solution_summary(model)"
      ],
      "metadata": {
        "id": "wrcTid9KWhYT",
        "outputId": "17947f78-cfa2-4bc7-ff8b-a9d88603d333",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running HiGHS 1.9.0 (git hash: 66f735e60): Copyright (c) 2024 HiGHS under MIT licence terms\n",
            "Coefficient ranges:\n",
            "  Matrix [2e+00, 8e+00]\n",
            "  Cost   [2e+00, 7e+00]\n",
            "  Bound  [1e+00, 1e+00]\n",
            "  RHS    [1e+01, 1e+01]\n",
            "Presolving model\n",
            "1 rows, 5 cols, 5 nonzeros  0s\n",
            "1 rows, 4 cols, 4 nonzeros  0s\n",
            "Objective function is integral with scale 1\n",
            "\n",
            "Solving MIP model with:\n",
            "   1 rows\n",
            "   4 cols (4 binary, 0 integer, 0 implied int., 0 continuous)\n",
            "   4 nonzeros\n",
            "\n",
            "Src: B => Branching; C => Central rounding; F => Feasibility pump; H => Heuristic; L => Sub-MIP;\n",
            "     P => Empty MIP; R => Randomized rounding; S => Solve LP; T => Evaluate node; U => Unbounded;\n",
            "     z => Trivial zero; l => Trivial lower; u => Trivial upper; p => Trivial point\n",
            "\n",
            "        Nodes      |    B&B Tree     |            Objective Bounds              |  Dynamic Constraints |       Work      \n",
            "Src  Proc. InQueue |  Leaves   Expl. | BestBound       BestSol              Gap |   Cuts   InLp Confl. | LpIters     Time\n",
            "\n",
            " z       0       0         0   0.00%   inf             -0                 Large        0     -1      0         0     0.0s\n",
            " T       0       0         0 100.00%   18              16                12.50%        0      0      0         1     0.0s\n",
            "         1       0         1 100.00%   16              16                 0.00%        0      0      0         1     0.0s\n",
            "\n",
            "Solving report\n",
            "  Status            Optimal\n",
            "  Primal bound      16\n",
            "  Dual bound        16\n",
            "  Gap               0% (tolerance: 0.01%)\n",
            "  P-D integral      5.24520874023e-06\n",
            "  Solution status   feasible\n",
            "                    16 (objective)\n",
            "                    0 (bound viol.)\n",
            "                    0 (int. viol.)\n",
            "                    0 (row viol.)\n",
            "  Timing            0.00 (total)\n",
            "                    0.00 (presolve)\n",
            "                    0.00 (solve)\n",
            "                    0.00 (postsolve)\n",
            "  Max sub-MIP depth 0\n",
            "  Nodes             1\n",
            "  Repair LPs        0 (0 feasible; 0 iterations)\n",
            "  LP iterations     1 (total)\n",
            "                    0 (strong br.)\n",
            "                    0 (separation)\n",
            "                    0 (heuristics)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "* Solver : HiGHS\n",
              "\n",
              "* Status\n",
              "  Result count       : 1\n",
              "  Termination status : OPTIMAL\n",
              "  Message from the solver:\n",
              "  \"kHighsModelStatusOptimal\"\n",
              "\n",
              "* Candidate solution (result #1)\n",
              "  Primal status      : FEASIBLE_POINT\n",
              "  Dual status        : NO_SOLUTION\n",
              "  Objective value    : 1.60000e+01\n",
              "  Objective bound    : 1.60000e+01\n",
              "  Relative gap       : 0.00000e+00\n",
              "  Dual objective value : NaN\n",
              "\n",
              "* Work counters\n",
              "  Solve time (sec)   : 1.91140e-03\n",
              "  Simplex iterations : 1\n",
              "  Barrier iterations : -1\n",
              "  Node count         : 1\n"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "items_chosen = [i for i in 1:n if value(x[i]) > 0.5]"
      ],
      "metadata": {
        "id": "OlwZVDDLWm2a",
        "outputId": "774b4e07-18bf-45ed-fecd-537a43353a97",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3-element Vector{Int64}:\n",
              " 1\n",
              " 4\n",
              " 5"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8RC1QNNqk6h1"
      },
      "source": [
        "# Need Help?\n",
        "\n",
        "* Learning: https://julialang.org/learning/\n",
        "* Documentation: https://docs.julialang.org/\n",
        "* Questions & Discussions:\n",
        "  * https://discourse.julialang.org/\n",
        "  * http://julialang.slack.com/\n",
        "  * https://stackoverflow.com/questions/tagged/julia\n",
        "\n",
        "If you ever ask for help or file an issue about Julia, you should generally provide the output of `versioninfo()`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2UMidUQB03vJ"
      },
      "source": [
        "Add new code cells by clicking the `+ Code` button (or _Insert_ > _Code cell_).\n",
        "\n",
        "Have fun!\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/JuliaLang/julia-logo-graphics/master/images/julia-logo-mask.png\" height=\"100\" />"
      ]
    }
  ]
}